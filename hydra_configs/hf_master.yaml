defaults:
  - _self_
  - lm_eval: superglue
  - corruption_robust: compound
  - other_gen: kgw

amlt: True

seed: 133337
device: cuda


model:
  name: 'microsoft/Phi-3-mini-4k-instruct' # 'meta-llama/Meta-Llama-3.1-8B' 'mistralai/Mistral-7B-v0.3' 'google/gemma-2-2b'  # 'meta-llama/Llama-2-7b-hf'  
  seed: ${seed}
  watermark_param_names:
    # - lm_head.weight
    # - 25@@@down_proj@@@weight
    # - 30@@@gate_proj@@@weight
    - 31@@@down_proj@@@weight
  watermark_variance: 1e-5
  watermark_loss: cross_entropy
  rank_to_drop: null # whether or not to use lowrank watermarker

  watermark_overrides: null # if not null, overrides the watermarking parameters
  robust_block_size: null # if not null, uses robust watermarking
  robust_num_samples: 10
  laserize: False
  load_prewatermarked: True

tokenizer:
  name: ${model.name}


data:
  name: allenai/c4
  subdata_name: realnewslike
  split: train
  max_samples: 1000
  truncation_type: 'fixed' # 'fixed' or 'random'
  prompt_field_name: text
  max_prompt_length: 100
  min_frac: 0.5
  max_frac: 1.0


sampling:
  top_p: 0.9
  top_k: -1 # Dont use
  temperature: 1.0
  seed: ${seed}
  max_tokens: 1000
  gpu_memory_utilization: 0.85
  max_num_seqs: 128




path_to_generations: null # if not null, pulls generations from blob mounted storage.


watermarking:
  verbose: False

master_parent: /home/blockadam/gaussian-watermarking


fs:
  blob_root: /mnt/default


hf_token_path: .hf_token